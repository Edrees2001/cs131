{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Tzr4O4Xz43m"
      },
      "source": [
        "# Spark MLlib Assignment\n",
        "This notebook completes the assignment tasks step by step using PySpark and MLlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LVntd-gfz43q"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj1mW_Nxz43s",
        "outputId": "4faf23e1-9cda-4c75-97a3-147de7ebf673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+------------+------------+------------+\n",
            "|passenger_count|PULocationID|DOLocationID|total_amount|\n",
            "+---------------+------------+------------+------------+\n",
            "|              1|         239|         239|         8.8|\n",
            "|              1|         230|         100|         8.3|\n",
            "|              1|          68|         127|       47.75|\n",
            "|              1|          68|          68|         7.3|\n",
            "|              1|          50|          42|       23.15|\n",
            "|              1|          95|         196|         9.8|\n",
            "|              1|         211|         211|         6.8|\n",
            "|              1|         237|         162|         7.8|\n",
            "|              1|         148|          37|        20.3|\n",
            "|              1|         265|         265|        0.31|\n",
            "+---------------+------------+------------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"TaxiFarePrediction\").getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\"2019 Taxi dataset.csv\", header=True, inferSchema=True)\n",
        "\n",
        "df = df.select(\"passenger_count\", \"PULocationID\", \"DOLocationID\", \"total_amount\")\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZCkUl0z3z43t"
      },
      "outputs": [],
      "source": [
        "\n",
        "trainDF, testDF = df.randomSplit([0.8, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZZ5dGA7rz43u"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "\n",
        "assembler = VectorAssembler(inputCols=[\"passenger_count\", \"PULocationID\", \"DOLocationID\"], outputCol=\"features\")\n",
        "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"total_amount\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dqVXEX8Cz43v"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[assembler, dt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ks-RH8Jfz43v"
      },
      "outputs": [],
      "source": [
        "model = pipeline.fit(trainDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfeJVObRz43w",
        "outputId": "97a155b4-91e7-4188-b6fa-a3868dded62d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+------------+------------+------------+-----------------+\n",
            "|passenger_count|PULocationID|DOLocationID|total_amount|       prediction|\n",
            "+---------------+------------+------------+------------+-----------------+\n",
            "|              1|          68|         127|       47.75|              7.3|\n",
            "|              1|         230|         100|         8.3|              7.8|\n",
            "|              1|         239|         239|         8.8|6.800000000000001|\n",
            "+---------------+------------+------------+------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions = model.transform(testDF)\n",
        "\n",
        "predictions.select(\"passenger_count\", \"PULocationID\", \"DOLocationID\", \"total_amount\", \"prediction\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQf99FEQz43x",
        "outputId": "00999b8b-4782-434d-c98d-d9dba095e3d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 23.384129233306936\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"total_amount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}